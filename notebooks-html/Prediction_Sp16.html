<div id="ipython-notebook">
            <a class="interact-button" href="https://mybinder.org/v2/gh/data-8/textbook/gh-pages?filepath=notebooks/Prediction_Sp16.ipynb">Interact</a>
            
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$']],
      processEscapes: true
    }
  });
</script>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the last section, we developed the concepts of correlation and regression as ways to describe data. We will now see how these concepts can become powerful tools for prediction, when used appropriately. In particular, given paired observations of two quantities and some additional observations of only the first quantity, we can infer typical values for the second quantity.</p>
<h2 id='Assumptions-of-randomness:-a-"regression-model"'>Assumptions of randomness: a "regression model"<a class="anchor-link" href='#Assumptions-of-randomness:-a-"regression-model"'>¶</a></h2><p>Prediction is possible if we believe that a scatter plot reflects the underlying relation between the two variables being plotted, but does not specify the relation completely. For example, a scatter plot of the heights of fathers and sons shows us the precise relation between the two variables in one particular sample of men; but we might wonder whether that relation holds true, or almost true, among all fathers and sons in the population from which the sample was drawn, or indeed among fathers and sons in general.</p>
<p>As always, inferential thinking begins with a careful examination of the assumptions about the data. Sets of assumptions are known as <em>models</em>. Sets of assumptions about randomness in roughly linear scatter plots are called <em>regression models</em>.</p>
<p>In brief, such models say that the underlying relation between the two variables is perfectly linear; this straight line is the <em>signal</em> that we would like to identify. However, we are not able to see the line clearly, because there is additional variability in the data beyond the relation. What we see are points that are scattered around the line. For each of the points, the linear signal that relates the two variables has been combined with some other source of variability that has nothing to do with the relation at all. This <em>random noise</em> obfuscates the linear signal, and it is our inferential goal to identify the signal despite the noise.</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In order to make these statements more precise, we will use the <code>np.random.normal</code> function, which generates samples from a normal distribution with 0 mean and 1 standard deviation. These samples correspond to a bell-shaped distribution expressed in standard units.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">()</span>
</pre></div></div></div>
<div class="output_text output_subarea output_execute_result">
<pre>-0.6423537870160524</pre></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">samples</span> <span class="o">=</span> <span class="n">Table</span><span class="p">(</span><span class="s1">'x'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10000</span><span class="p">):</span>
    <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">()])</span>
<span class="n">samples</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">))</span>
</pre></div></div></div>
<div class="output_png output_subarea ">
<img src="/notebooks-images/Prediction_Sp16_5_0.png"/></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The regression model specifies that the points in a scatter plot, measured in standard units, are generated at random as follows.</p>
<ul>
<li><p>The <code>x</code> are sampled from the normal distribution.</p>
</li>
<li><p>For each <code>x</code>, its corresponding <code>y</code> is sampled using the <code>signal_and_noise</code> function below, which takes <code>x</code> and the correlation coefficient <code>r</code>.</p>
</li>
</ul></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">signal_and_noise</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">r</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">()</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">r</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mf">0.5</span>
</pre></div></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For example, if we choose <code>r</code> to be a half, then the following scatter diagram might result.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">regression_model</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">sample_size</span><span class="p">):</span>
    <span class="n">pairs</span> <span class="o">=</span> <span class="n">Table</span><span class="p">([</span><span class="s1">'x'</span><span class="p">,</span> <span class="s1">'y'</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">sample_size</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">()</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">signal_and_noise</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
        <span class="n">pairs</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">pairs</span>

<span class="n">regression_model</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="s1">'x'</span><span class="p">,</span> <span class="s1">'y'</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_png output_subarea ">
<img src="/notebooks-images/Prediction_Sp16_9_0.png"/></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Based on this scatter plot, how should we estimate the true line? The best line that we can put through a scatter plot is the regression line. So the regression line is a natural estimate of the true line.</p>
<p>The simulation below draws both the true line used to generate the data (green) and the regression line (blue) found by analyzing the pairs that were generated.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">compare</span><span class="p">(</span><span class="n">true_r</span><span class="p">,</span> <span class="n">sample_size</span><span class="p">):</span>
    <span class="n">pairs</span> <span class="o">=</span> <span class="n">regression_model</span><span class="p">(</span><span class="n">true_r</span><span class="p">,</span> <span class="n">sample_size</span><span class="p">)</span>
    <span class="n">estimated_r</span> <span class="o">=</span> <span class="n">correlation</span><span class="p">(</span><span class="n">pairs</span><span class="p">,</span> <span class="s1">'x'</span><span class="p">,</span> <span class="s1">'y'</span><span class="p">)</span>
    <span class="n">pairs</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="s1">'x'</span><span class="p">,</span> <span class="s1">'y'</span><span class="p">,</span> <span class="n">fit_line</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">3</span> <span class="o">*</span> <span class="n">true_r</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">true_r</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">'g'</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"The true r is "</span><span class="p">,</span> <span class="n">true_r</span><span class="p">,</span> <span class="s2">" and the estimated r is "</span><span class="p">,</span> <span class="n">estimated_r</span><span class="p">)</span>

<span class="n">compare</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>The true r is  0.5  and the estimated r is  0.459672161067
</pre></div>
<div class="output_png output_subarea ">
<img src="/notebooks-images/Prediction_Sp16_11_1.png"/></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>With 1000 samples, we see that the true line and the regression line are quite similar. With fewer samples, the regression estimate of the true line that generated the data may be quite different.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">compare</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>The true r is  0.5  and the estimated r is  0.627329170668
</pre></div>
<div class="output_png output_subarea ">
<img src="/notebooks-images/Prediction_Sp16_13_1.png"/></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>With very few samples, the regression line may have a clear positive or negative slope, even when the true relationship has a correlation of 0.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">compare</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>The true r is  0  and the estimated r is  0.501582566452
</pre></div>
<div class="output_png output_subarea ">
<img src="/notebooks-images/Prediction_Sp16_15_1.png"/></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>With real data, we will never observe the true line. In fact, regression is often applied when we are uncertain whether the true relation between two quantities is linear at all.  What the simulation shows that if the regression model looks plausible, and we have a large sample, then regression line is a good approximation to the true line.</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Predictions">Predictions<a class="anchor-link" href="#Predictions">¶</a></h2><p>Here is an example where regression model can be used to make predictions.</p>
<p>The data are a subset of the information gathered in a randomized controlled trial about treatments for Hodgkin's disease. Hodgkin's disease is a cancer that typically affects young people. The disease is curable but the treatment is very harsh. The purpose of the trial was to come up with dosage that would cure the cancer but minimize the adverse effects on the patients.</p>
<p>This table <code>hodgkins</code> contains data on the effect that the treatment had on the lungs of 22 patients. The columns are:</p>
<ul>
<li>Height in cm</li>
<li>A measure of radiation to the mantle (neck, chest, under arms)</li>
<li>A measure of chemotherapy</li>
<li>A score of the health of the lungs at baseline, that is, at the start of the treatment; higher scores correspond to more healthy lungs</li>
<li>The same score of the health of the lungs, 15 months after treatment</li>
</ul></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hodgkins</span> <span class="o">=</span> <span class="n">Table</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="s1">'hodgkins.csv'</span><span class="p">)</span>
<span class="n">hodgkins</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div></div></div>
<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
    <thead>
        <tr>
            <th>height</th> <th>rad</th> <th>chemo</th> <th>base</th> <th>month15</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>164   </td> <td>679 </td> <td>180  </td> <td>160.57</td> <td>87.77  </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>168   </td> <td>311 </td> <td>180  </td> <td>98.24 </td> <td>67.62  </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>173   </td> <td>388 </td> <td>239  </td> <td>129.04</td> <td>133.33 </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>157   </td> <td>370 </td> <td>168  </td> <td>85.41 </td> <td>81.28  </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>160   </td> <td>468 </td> <td>151  </td> <td>67.94 </td> <td>79.26  </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>170   </td> <td>341 </td> <td>96   </td> <td>150.51</td> <td>80.97  </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>163   </td> <td>453 </td> <td>134  </td> <td>129.88</td> <td>69.24  </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>175   </td> <td>529 </td> <td>264  </td> <td>87.45 </td> <td>56.48  </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>185   </td> <td>392 </td> <td>240  </td> <td>149.84</td> <td>106.99 </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>178   </td> <td>479 </td> <td>216  </td> <td>92.24 </td> <td>73.43  </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>179   </td> <td>376 </td> <td>160  </td> <td>117.43</td> <td>101.61 </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>181   </td> <td>539 </td> <td>196  </td> <td>129.75</td> <td>90.78  </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>173   </td> <td>217 </td> <td>204  </td> <td>97.59 </td> <td>76.38  </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>166   </td> <td>456 </td> <td>192  </td> <td>81.29 </td> <td>67.66  </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>170   </td> <td>252 </td> <td>150  </td> <td>98.29 </td> <td>55.51  </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>165   </td> <td>622 </td> <td>162  </td> <td>118.98</td> <td>90.92  </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>173   </td> <td>305 </td> <td>213  </td> <td>103.17</td> <td>79.74  </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>174   </td> <td>566 </td> <td>198  </td> <td>94.97 </td> <td>93.08  </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>173   </td> <td>322 </td> <td>119  </td> <td>85    </td> <td>41.96  </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>173   </td> <td>270 </td> <td>160  </td> <td>115.02</td> <td>81.12  </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>183   </td> <td>259 </td> <td>241  </td> <td>125.02</td> <td>97.18  </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>188   </td> <td>238 </td> <td>252  </td> <td>137.43</td> <td>113.2  </td>
        </tr>
    </tbody>
</table></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It is evident that the patients' lungs were less healthy 15 months after the treatment than at baseline. At 36 months, they did recover most of their lung function, but those data are not part of this table.</p>
<p>The scatter plot below shows that taller patients had higher scores at 15 months.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hodgkins</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="s1">'height'</span><span class="p">,</span> <span class="s1">'month15'</span><span class="p">,</span> <span class="n">fit_line</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_png output_subarea ">
<img src="/notebooks-images/Prediction_Sp16_20_0.png"/></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The scatter plot looks roughly linear. Let us assume that the regression model holds. Under that assumption, the regression line can be used to predict the 15-month score of a new patient, based on the patient's height. The prediction will be good provided the assumptions of the regression model are justified for these data, and provided the new patient is similar to those in the study.</p>
<p>The function <code>regress</code> gives us the slope and intercept of the regression line. To predict the 15-month score of a new patient whose height is $x$ cm, we use the following calculation:</p>
<p>Predicted 15-month score of a patient who is $x$ inches tall
$~=~$ slope$\;\times\;x ~+~$ intercept</p>
<p>The predicted 15-month score of a patient who is 173 cm tall is 83.66 cm, and that of a patient who is 163 cm tall is 73.69 cm.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># slope and intercept</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">slope</span><span class="p">(</span><span class="n">hodgkins</span><span class="p">,</span> <span class="s1">'height'</span><span class="p">,</span> <span class="s1">'month15'</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">intercept</span><span class="p">(</span><span class="n">hodgkins</span><span class="p">,</span> <span class="s1">'height'</span><span class="p">,</span> <span class="s1">'month15'</span><span class="p">)</span>
</pre></div></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># New patient, 173 cm tall</span>
<span class="c1"># Predicted 15-month score:</span>

<span class="n">a</span> <span class="o">*</span> <span class="mi">173</span> <span class="o">+</span> <span class="n">b</span>
</pre></div></div></div>
<div class="output_text output_subarea output_execute_result">
<pre>83.65699801460444</pre></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># New patient, 163 cm tall</span>
<span class="c1"># Predicted 15-month score:</span>

<span class="n">a</span> <span class="o">*</span> <span class="mi">163</span> <span class="o">+</span> <span class="n">b</span>
</pre></div></div></div>
<div class="output_text output_subarea output_execute_result">
<pre>73.694360467072741</pre></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The logic of regression prediction can be wrapped in a function <code>predict</code> that takes a table, the two columns of interest, and some new value for <code>x</code>. It predicts the average value for <code>y</code>.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">new_x_value</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">slope</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">intercept</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">a</span> <span class="o">*</span> <span class="n">new_x_value</span> <span class="o">+</span> <span class="n">b</span>

<span class="n">predict</span><span class="p">(</span><span class="n">hodgkins</span><span class="p">,</span> <span class="s1">'height'</span><span class="p">,</span> <span class="s1">'month15'</span><span class="p">,</span> <span class="mi">163</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_text output_subarea output_execute_result">
<pre>73.694360467072741</pre></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Variability-of-the-Prediction">Variability of the Prediction<a class="anchor-link" href="#Variability-of-the-Prediction">¶</a></h2><p>As data scientists working under the regression model, we must always remain aware that a sample might have been different. Had the sample been different, the regression line would have been different too, and so would our prediction.</p>
<p>To understand how much a prediction might vary, we can select different samples from the data we have. Below, we select only 15 of the 22 rows of the <code>hodgkins</code> table at random without replacement, then makes a prediction.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">predict</span><span class="p">(</span><span class="n">hodgkins</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">15</span><span class="p">),</span> <span class="s1">'height'</span><span class="p">,</span> <span class="s1">'month15'</span><span class="p">,</span> <span class="mi">163</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_text output_subarea output_execute_result">
<pre>71.653856125189805</pre></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The prediction is different, but how much might we expect it to differ? From a single sample, it is not possible to answer this question. The simulation below draws 1000 samples of 15 rows each, then draws a histogram of the predicted values using each sample.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sample_predict</span><span class="p">(</span><span class="n">new_x_value</span><span class="p">):</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">Table</span><span class="p">([</span><span class="s1">'Predictions'</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
        <span class="n">predicted</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">hodgkins</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">15</span><span class="p">),</span> <span class="s1">'height'</span><span class="p">,</span> <span class="s1">'month15'</span><span class="p">,</span> <span class="n">new_x_value</span><span class="p">)</span>
        <span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">predicted</span><span class="p">])</span>
    <span class="n">predictions</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

<span class="n">sample_predict</span><span class="p">(</span><span class="mi">163</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_png output_subarea ">
<img src="/notebooks-images/Prediction_Sp16_30_0.png"/></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Using only 15 rows instead of all 22, the prediction could have come out differently from 73.69. This histogram shows how different the prediction might be. Almost all predictions fall between 64 and 82, but a few are outside of this range.</p>
<p>For an <code>x</code> value that is closer to the mean of all heights, the predictions from 15 rows are more tightly clustered.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sample_predict</span><span class="p">(</span><span class="mi">173</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_png output_subarea ">
<img src="/notebooks-images/Prediction_Sp16_32_0.png"/></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this histogram of the predictions for a height of 173, we see that almost all predictions fall between 76 and 90. The narrow range 80 to 86 accounts for nearly 70% of the estimates.</p>
<p>Predictions of values outside the typical observations of height vary wildly. A data scientist is rarely justified in extrapolating a linear trend beyond the range of values observed.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sample_predict</span><span class="p">(</span><span class="mi">150</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_png output_subarea ">
<img src="/notebooks-images/Prediction_Sp16_34_0.png"/></div></div>