<div id="ipython-notebook">
            <a class="interact-button" href="http://datahub.berkeley.edu/user-redirect/interact?repo=textbook&path=notebooks/Empirical_Distributions.ipynb">Interact</a>
            
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$']],
      processEscapes: true
    }
  });
</script>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Empirical-Distributions">Empirical Distributions<a class="anchor-link" href="#Empirical-Distributions">¶</a></h3><p>Much of data science involves data from large random samples. In this section we will examine some properties of such samples.</p>
<p>We will start with a simple experiment: rolling a die multiple times and keeping track of which face appears. The table <code>die</code> contains the numbers of spots on the faces of a die. All the numbers appear exactly once, as we are assuming that the die is fair.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">die</span> <span class="o">=</span> <span class="n">Table</span><span class="p">()</span><span class="o">.</span><span class="n">with_column</span><span class="p">(</span><span class="s1">'Face'</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">die</span>
</pre></div></div></div>
<div class="output_html rendered_html output_subarea output_execute_result">
<table border="1" class="dataframe">
    <thead>
        <tr>
            <th>Face</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>1   </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>2   </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>3   </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>4   </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>5   </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>6   </td>
        </tr>
    </tbody>
</table></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="A-Probability-Distribution">A Probability Distribution<a class="anchor-link" href="#A-Probability-Distribution">¶</a></h3><p>The histogram below helps us visualize the fact that every face appears with probability 1/6. We say that the histogram shows the <em>distribution</em> of probabilities over all the possible faces. Since all the bars represent the same percent chance, the distribution is called <em>uniform on the integers 1 through 6.</em></p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">die_bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">6.6</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">die</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span> <span class="o">=</span> <span class="n">die_bins</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_png output_subarea ">
<img src="/notebooks-images/Empirical_Distributions_4_0.png"/></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Variables whose successive values are separated by the same fixed amount, such as the values on rolls of a die (successive values separated by 1), are called <em>discrete</em>. The histogram above is called a <em>discrete</em> histogram. Its bins are specified by the array <code>die_bins</code> and ensure that each bar is centered over the corresponding integer value.</p>
<p>It is important to remember that the die can't show 1.3 spots, or 5.2 spots – it always shows an integer number of spots. But our visualization spreads the probability of each value over the area of a bar. While this might seem a bit arbitrary at this stage of the course, it will become important later when we overlay smooth curves over discrete histograms.</p>
<p>Before going further, let's make sure that the numbers on the axes make sense. The probability of each face is 1/6, which is 16.67% when rounded to two decimal places. The width of each bin is 1 unit. So the height of each bar is 16.67% per unit. This agrees with the horizontal and vertical scales of the graph.</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Empirical-Distributions">Empirical Distributions<a class="anchor-link" href="#Empirical-Distributions">¶</a></h3><p>The distribution above consists of the theoretical probability of each face. It is not based on data. It can be studied and understood without any dice being rolled.</p>
<p><em>Empirical distributions,</em> on the other hand, are distributions of observed data. They can be visualized by <em>empirical histograms</em>.</p>
<p>Let us get some data by simulating rolls of a die. This can be done by sampling at random with replacement from the integers 1 through 6. To do this using Python, we will use the Table method <code>sample</code>, which draws at random with replacement from the rows of a table. Its argument is the sample size, and it returns a table consisting of the rows that were selected. An optional argument <code>with_replacement=False</code> specifies that the sample should be drawn without replacement, but that does not apply to rolling a die.</p>
<p>Here are the results of 10 rolls of a die.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">die</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_html rendered_html output_subarea output_execute_result">
<table border="1" class="dataframe">
    <thead>
        <tr>
            <th>Face</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>5   </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>3   </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>3   </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>4   </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>2   </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>2   </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>4   </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>1   </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>6   </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>6   </td>
        </tr>
    </tbody>
</table></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can use the same method to simulate as many rolls as we like, and then draw empirical histograms of the results. Because we are going to do this repeatedly, we define a function <code>empirical_hist_die</code> that takes as its argument the sample size; the function rolls the die as many times as its argument and then draws a histogram.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">empirical_hist_die</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="n">die</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span> <span class="o">=</span> <span class="n">die_bins</span><span class="p">)</span>
</pre></div></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Empirical-Histograms">Empirical Histograms<a class="anchor-link" href="#Empirical-Histograms">¶</a></h3><p>Here is an empirical histogram of 10 rolls. It doesn't look very much like the probability histogram above. Run the cell a few times to see how it varies.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">empirical_hist_die</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_png output_subarea ">
<img src="/notebooks-images/Empirical_Distributions_11_0.png"/></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>When the sample size increases, the empirical histogram begins to look more like the histogram of theoretical probabilities.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">empirical_hist_die</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_png output_subarea ">
<img src="/notebooks-images/Empirical_Distributions_13_0.png"/></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">empirical_hist_die</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_png output_subarea ">
<img src="/notebooks-images/Empirical_Distributions_14_0.png"/></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As we increase the number of rolls in the simulation, the area of each bar gets closer 16.67%, which is the area of each bar in the probability histogram.</p>
<p>What we have observed in an instance of a general rule:</p>
<h3 id="The-Law-of-Averages">The Law of Averages<a class="anchor-link" href="#The-Law-of-Averages">¶</a></h3><p>If a chance experiment is repeated independently and under identical conditions, then, in the long run, the proportion of times that an event occurs gets closer and closer to the theoretical probability of the event.</p>
<p>For example, in the long run, the proportion of times the face with four spots appears gets closer and closer to 1/6.</p>
<p>Here "independently and under identical conditions" means that every repetition is performed in the same way regardless of the results of all the other repetitions.</p></div></div></div>