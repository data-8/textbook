<div id="ipython-notebook">
            <a class="interact-button" href="http://datahub.berkeley.edu/user-redirect/interact?repo=textbook&path=notebooks/birds.csv&path=notebooks/Multiple2.ipynb">Interact</a>
            
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$']],
      processEscapes: true
    }
  });
</script>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Correlated-Predictors">Correlated Predictors<a class="anchor-link" href="#Correlated-Predictors">¶</a></h2><p>Correlations between predictor variables are important factors in selecting the set of predictors to use in a regression model. Here is an example that demonstrates some of the considerations that are involved in variable selection.</p>
<p>The data consist of measurements on the eggs of a species of small bird, as recorded by Abrahams and Rizzardi in the BLSS statistical system. The goal is to use dimensions of an egg to estimate the weight of the bird that hatches from the egg; as bigger hatchlings are more likely to survive, the estimates can be used to help predict the population size of the species.</p>
<p>The variables are:</p>
<ul>
<li><code>e_length</code>: the length of the egg, in millimeters</li>
<li><code>e_breadth</code>: the width of the egg at its widest part, in millimeters</li>
<li><code>e_weight</code>: the weight of the egg, in grams</li>
<li><code>b_weight</code>: the weight of the bird that hatched from the egg, in grams</li>
</ul></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">birds</span> <span class="o">=</span> <span class="n">Table</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="s1">'birds.csv'</span><span class="p">)</span>
<span class="n">birds</span>
</pre></div></div></div>
<div class="output_html rendered_html output_subarea output_execute_result">
<table border="1" class="dataframe">
    <thead>
        <tr>
            <th>e_length</th> <th>e_breadth</th> <th>e_weight</th> <th>b_weight</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>28.8    </td> <td>21.84    </td> <td>7.4     </td> <td>5.2     </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>29.04   </td> <td>22.45    </td> <td>7.7     </td> <td>5.4     </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>29.36   </td> <td>22.48    </td> <td>7.9     </td> <td>5.6     </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>30.1    </td> <td>21.71    </td> <td>7.5     </td> <td>5.3     </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>30.17   </td> <td>22.75    </td> <td>8.3     </td> <td>5.9     </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>30.34   </td> <td>22.84    </td> <td>8.5     </td> <td>5.8     </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>30.36   </td> <td>22.5     </td> <td>8.2     </td> <td>5.8     </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>30.46   </td> <td>22.72    </td> <td>8.3     </td> <td>6       </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>30.54   </td> <td>23.31    </td> <td>9       </td> <td>6.1     </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>30.62   </td> <td>22.94    </td> <td>8.5     </td> <td>6.2     </td>
        </tr>
    </tbody>
</table>
<p>... (34 rows omitted)</p></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In order to estimate <code>b_weight</code> based on a combination of the other variables, we will start by examining the correlation matrix. Not surprisingly, the variable most highly correlated with the weight of the bird is the weight of the egg, <code>e_weight</code>. But the linear dimensions <code>e_length</code> and <code>e_breadth</code> are also quite highly correlated with <code>b_weight</code>; also, all the dimensions of the egg are correlated with each other.</p></div></div>
<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>e_length</th>
      <th>e_breadth</th>
      <th>e_weight</th>
      <th>b_weight</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>e_length</th>
      <td>1.000000</td>
      <td>0.402764</td>
      <td>0.792449</td>
      <td>0.676142</td>
    </tr>
    <tr>
      <th>e_breadth</th>
      <td>0.402764</td>
      <td>1.000000</td>
      <td>0.839077</td>
      <td>0.733687</td>
    </tr>
    <tr>
      <th>e_weight</th>
      <td>0.792449</td>
      <td>0.839077</td>
      <td>1.000000</td>
      <td>0.847228</td>
    </tr>
    <tr>
      <th>b_weight</th>
      <td>0.676142</td>
      <td>0.733687</td>
      <td>0.847228</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The scatter plot of the weight of the bird and the weight of the egg is shown below, along with the regression line. Just based on the graph, it is reasonable to conclude that the fit is fairly good.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">scatter_fit</span><span class="p">(</span><span class="n">birds</span><span class="p">,</span> <span class="s1">'e_weight'</span><span class="p">,</span> <span class="s1">'b_weight'</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_png output_subarea ">
<img src="/notebooks-images/Multiple2_7_0.png"/></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The summary statistics confirm this assessment. For example $R^2$ is quite high: 0.718. The 95% confidence interval for the slope does not contain 0. All of this points to a genuine linear trend in the relation between the weight of the egg and the weight of the bird that hatches from the egg.</p></div></div>
<div class="output_html rendered_html output_subarea output_execute_result">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tbody><tr>
  <th>Dep. Variable:</th>        <td>b_weight</td>     <th>  R-squared:         </th> <td>   0.718</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.711</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   106.8</td>
</tr>
<tr>
  <th>Date:</th>             <td>Sat, 05 Dec 2015</td> <th>  Prob (F-statistic):</th> <td>4.15e-13</td>
</tr>
<tr>
  <th>Time:</th>                 <td>15:16:55</td>     <th>  Log-Likelihood:    </th> <td>  5.0722</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    44</td>      <th>  AIC:               </th> <td>  -6.144</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>    42</td>      <th>  BIC:               </th> <td>  -2.576</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
      <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P&gt;|t|</th> <th>[95.0% Conf. Int.]</th> 
</tr>
<tr>
  <th>const</th>    <td>   -0.0583</td> <td>    0.601</td> <td>   -0.097</td> <td> 0.923</td> <td>   -1.271     1.155</td>
</tr>
<tr>
  <th>e_weight</th> <td>    0.7185</td> <td>    0.070</td> <td>   10.336</td> <td> 0.000</td> <td>    0.578     0.859</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
  <th>Omnibus:</th>       <td> 2.737</td> <th>  Durbin-Watson:     </th> <td>   1.797</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.254</td> <th>  Jarque-Bera (JB):  </th> <td>   1.986</td>
</tr>
<tr>
  <th>Skew:</th>          <td>-0.033</td> <th>  Prob(JB):          </th> <td>   0.370</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 4.039</td> <th>  Cond. No.          </th> <td>    158.</td>
</tr>
</tbody></table></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It is interesting to see what happens when we use all of the dimensions of the egg – length, breadth, and weight – as predictors. Compared to the simple regression based on egg weight alone, there is only a tiny increase in $R^2$: 0.724 compared to 0.718. Also, the adjusted $R^2$ goes down slightly, from 0.711 to 0.703. There is no substantial gain in throwing in the linear dimensions of the egg as predictors, compared to using just egg weight alone.</p></div></div>
<div class="output_html rendered_html output_subarea output_execute_result">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tbody><tr>
  <th>Dep. Variable:</th>        <td>b_weight</td>     <th>  R-squared:         </th> <td>   0.724</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.703</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.98</td>
</tr>
<tr>
  <th>Date:</th>             <td>Sat, 05 Dec 2015</td> <th>  Prob (F-statistic):</th> <td>2.90e-11</td>
</tr>
<tr>
  <th>Time:</th>                 <td>15:17:03</td>     <th>  Log-Likelihood:    </th> <td>  5.5617</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    44</td>      <th>  AIC:               </th> <td>  -3.123</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>    40</td>      <th>  BIC:               </th> <td>   4.013</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P&gt;|t|</th> <th>[95.0% Conf. Int.]</th> 
</tr>
<tr>
  <th>const</th>     <td>   -4.6057</td> <td>    4.843</td> <td>   -0.951</td> <td> 0.347</td> <td>  -14.394     5.183</td>
</tr>
<tr>
  <th>e_weight</th>  <td>    0.4312</td> <td>    0.317</td> <td>    1.360</td> <td> 0.181</td> <td>   -0.209     1.072</td>
</tr>
<tr>
  <th>e_breadth</th> <td>    0.2159</td> <td>    0.229</td> <td>    0.944</td> <td> 0.351</td> <td>   -0.246     0.678</td>
</tr>
<tr>
  <th>e_length</th>  <td>    0.0666</td> <td>    0.083</td> <td>    0.803</td> <td> 0.426</td> <td>   -0.101     0.234</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
  <th>Omnibus:</th>       <td> 3.670</td> <th>  Durbin-Watson:     </th> <td>   1.716</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.160</td> <th>  Jarque-Bera (JB):  </th> <td>   3.399</td>
</tr>
<tr>
  <th>Skew:</th>          <td>-0.029</td> <th>  Prob(JB):          </th> <td>   0.183</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 4.360</td> <th>  Cond. No.          </th> <td>5.74e+03</td>
</tr>
</tbody></table></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Collinearity">Collinearity<a class="anchor-link" href="#Collinearity">¶</a></h3><p>That too many predictor variables have been used in this regression is most apparent when you look at the confidence intervals for the slopes. All of the intervals contain 0, so it appears that there could be no linear trend in the relation between the response variable and the predictors. Yet $R^2$ is high. How can we reconcile these two apparently contradictory observations?</p>
<p>The answer lies in the correlation matrix. It shows that the three predictor variables are all correlated with each other. This is called <em>collinearity</em>. Because of collinearity, none of the slopes has a clear practical interpretation: it is not possible to increase one of the predictor variables while holding the others constant.</p>
<p>Therefore this regression gives little indication of how each individual predictor variable affects the estimate of the response. The small increase in $R^2$ has been obtained at a steep price: the interpretability of the model.</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The problem of collinearity can be mitigated by choosing the predictors more carefully. The correlation matrix shows that egg weight is highly correlated with both egg length and egg breadth. However, the correlation between egg length and egg breadth is much smaller. So it is a reasonable to regress bird weight on just the two linear dimensions of the egg.</p></div></div>
<div class="output_png output_subarea ">
<img src="/notebooks-images/Multiple2_14_0.png"/></div>
<div class="output_html rendered_html output_subarea output_execute_result">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tbody><tr>
  <th>Dep. Variable:</th>        <td>b_weight</td>     <th>  R-squared:         </th> <td>   0.711</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.697</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   50.49</td>
</tr>
<tr>
  <th>Date:</th>             <td>Sat, 05 Dec 2015</td> <th>  Prob (F-statistic):</th> <td>8.73e-12</td>
</tr>
<tr>
  <th>Time:</th>                 <td>15:17:34</td>     <th>  Log-Likelihood:    </th> <td>  4.5668</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    44</td>      <th>  AIC:               </th> <td>  -3.134</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>    41</td>      <th>  BIC:               </th> <td>   2.219</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P&gt;|t|</th> <th>[95.0% Conf. Int.]</th> 
</tr>
<tr>
  <th>const</th>     <td>  -10.7386</td> <td>    1.788</td> <td>   -6.007</td> <td> 0.000</td> <td>  -14.349    -7.128</td>
</tr>
<tr>
  <th>e_breadth</th> <td>    0.5057</td> <td>    0.084</td> <td>    6.006</td> <td> 0.000</td> <td>    0.336     0.676</td>
</tr>
<tr>
  <th>e_length</th>  <td>    0.1695</td> <td>    0.034</td> <td>    4.955</td> <td> 0.000</td> <td>    0.100     0.239</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
  <th>Omnibus:</th>       <td> 4.685</td> <th>  Durbin-Watson:     </th> <td>   1.648</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.096</td> <th>  Jarque-Bera (JB):  </th> <td>   5.379</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.016</td> <th>  Prob(JB):          </th> <td>  0.0679</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 4.713</td> <th>  Cond. No.          </th> <td>2.04e+03</td>
</tr>
</tbody></table></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This regression can be much more clearly interpreted than the regression based on all three predictors. The value of $R^2$ is just over 0.7, and the confidence intervals for the two slopes don't contain 0. Because of the relative lack of collinearity between the two predictors, each slope has meaning.</p>
<p>Indeed, the regression based on the two linear dimensions of the egg is quite comparable to the simple regression based on egg weight. To see why, let us examine the relation between egg weight and the two linear dimensions. How can we do this?</p>
<p>A good way is to use the technique that we have been using all through this section: multiple regression. Let's see what happens when we try to estimate egg weight based on egg length and egg breadth.</p></div></div>
<div class="output_html rendered_html output_subarea output_execute_result">
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tbody><tr>
  <th>Dep. Variable:</th>        <td>e_weight</td>     <th>  R-squared:         </th> <td>   0.951</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   394.6</td>
</tr>
<tr>
  <th>Date:</th>             <td>Sat, 05 Dec 2015</td> <th>  Prob (F-statistic):</th> <td>1.65e-27</td>
</tr>
<tr>
  <th>Time:</th>                 <td>15:17:41</td>     <th>  Log-Likelihood:    </th> <td>  36.169</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    44</td>      <th>  AIC:               </th> <td>  -66.34</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>    41</td>      <th>  BIC:               </th> <td>  -60.98</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P&gt;|t|</th> <th>[95.0% Conf. Int.]</th> 
</tr>
<tr>
  <th>const</th>     <td>  -14.2220</td> <td>    0.872</td> <td>  -16.314</td> <td> 0.000</td> <td>  -15.983   -12.461</td>
</tr>
<tr>
  <th>e_breadth</th> <td>    0.6719</td> <td>    0.041</td> <td>   16.367</td> <td> 0.000</td> <td>    0.589     0.755</td>
</tr>
<tr>
  <th>e_length</th>  <td>    0.2386</td> <td>    0.017</td> <td>   14.308</td> <td> 0.000</td> <td>    0.205     0.272</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
  <th>Omnibus:</th>       <td> 1.287</td> <th>  Durbin-Watson:     </th> <td>   2.036</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.526</td> <th>  Jarque-Bera (JB):  </th> <td>   0.605</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.250</td> <th>  Prob(JB):          </th> <td>   0.739</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 3.281</td> <th>  Cond. No.          </th> <td>2.04e+03</td>
</tr>
</tbody></table></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Notice the extremely high value of $R^2$. This indicates that egg weight is very close to a linear function of egg length and egg breadth. Therefore, the information in egg weight as a predictor of bird weight is essentially the same as the information in a linear function of egg length and breadth. For confirmation, here is the scatter plot of the three variables. As you can see, the points are closely clustered about a plane.</p></div></div>
<div class="output_png output_subarea ">
<img src="/notebooks-images/Multiple2_19_0.png"/></div></div>