<div id="ipython-notebook">
            <a class="interact-button" href="https://mybinder.org/v2/gh/data-8/textbook/gh-pages?filepath=notebooks/Binomial.ipynb">Interact</a>
            
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$']],
      processEscapes: true
    }
  });
</script>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Binomial-and-Multinomial-Models">Binomial and Multinomial Models<a class="anchor-link" href="#Binomial-and-Multinomial-Models">¶</a></h2><p>In the past few sections we have spent some time on inference in the setting of the classical regression model. But in fact we have used chance models all along. An important class of models appeared, albeit informally, when we studied the randomness in the selection of jury panels, back in Chapter 3. Let us examine those a little more carefully, to exactly how the chances come in.</p>
<p>For ease of reference, here is one of the examples from Chapter 3.</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="U.S.-Supreme-Court,-1965:-Swain-vs.-Alabama">U.S. Supreme Court, 1965: Swain vs. Alabama<a class="anchor-link" href="#U.S.-Supreme-Court,-1965:-Swain-vs.-Alabama">¶</a></h3><p>In the early 1960's, in Talladega County in Alabama, a black man called Robert Swain was convicted of raping a white woman and was sentenced to death. He appealed his sentence, citing among other factors the all-white jury. At the time, only men aged 21 or older were allowed to serve on juries in Talladega County. In the county, 26% of the eligible jurors were black, but there were only 8 black men among the 100 selected for the jury panel in Swain's trial. No black man was selected for the trial jury.</p>
<p>In 1965, the Supreme Court of the United States denied Swain's appeal. In its ruling, the Court wrote "... the overall percentage disparity has been small and reflects no studied attempt to include or exclude a specified number of Negroes."</p>
<p>Let us use the methods we have developed to examine the disparity between 8 out of 100 and 26 out of 100 black men in a panel drawn at random from among the eligible jurors.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">AL_jury_rows</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="s2">"Black"</span><span class="p">,</span>  <span class="mf">0.26</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">"Other"</span><span class="p">,</span> <span class="mf">0.74</span><span class="p">]</span>
<span class="p">]</span>
<span class="n">AL_jury</span> <span class="o">=</span> <span class="n">Table</span><span class="o">.</span><span class="n">from_rows</span><span class="p">(</span><span class="n">AL_jury_rows</span><span class="p">,</span> <span class="p">[</span><span class="s2">"Race"</span><span class="p">,</span> <span class="s2">"Eligible"</span><span class="p">])</span>
<span class="n">AL_jury</span>
</pre></div></div></div>
<div class="output_html rendered_html output_subarea output_execute_result">
<table border="1" class="dataframe">
    <thead>
        <tr>
            <th>Race</th> <th>Eligible</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Black</td> <td>0.26    </td>
        </tr>
    </tbody>
        <tbody><tr>
            <td>Other</td> <td>0.74    </td>
        </tr>
    </tbody>
</table></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Null:</strong> Jury panel is like a random sample from the population of eligible jurors; that is, like the number of heads in 100 tosses of a coin that lands heads with chance 0.26.</p>
<p><strong>Alternative:</strong> Jury panel is not like a random sample from the population of eligible jurors.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Statistic: number black in sample of size 100</span>
<span class="c1"># Observed value of statistic: 8</span>

<span class="c1"># Compute the empirical distribution of the test statistic</span>

<span class="n">sample_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">repetitions</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">eligible</span> <span class="o">=</span> <span class="n">AL_jury</span><span class="p">[</span><span class="s2">"Eligible"</span><span class="p">]</span>

<span class="n">black_in_sample</span> <span class="o">=</span> <span class="n">Table</span><span class="p">([[]],</span> <span class="p">[</span><span class="s2">"Number black"</span><span class="p">])</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">repetitions</span><span class="p">):</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">sample_size</span><span class="p">,</span> <span class="n">eligible</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">black_in_sample</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">b</span><span class="p">])</span>

<span class="n">black_in_sample</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">normed</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plots</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">plots</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plots</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"number black in sample of 100 (under null)"</span><span class="p">)</span>
<span class="n">plots</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Empirical Distribution'</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.text.Text at 0x10a849a20&gt;</pre></div>
<div class="output_png output_subarea ">
<img src="/notebooks-images/Binomial_5_1.png"/></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As we noted in Chapter 3, the observed number of 8 black men on the jury panel is not consistent with the distribution above, computed under the null hypothesis. Therefore the data support the alternative: the panel was not selected at random.</p>
<p>Our goal here is to examine in detail the probability distribution of the number of black men on the panel, assuming random selection. Th empirical distribution above approximates that probability distribution. But can we say exactly what that distribution is?</p>
<p>We know that the probability distribution of the number of black men in a randomly selected group of 100 jurors can be found by forming all possible samples of 100 jurors, counting the number of black men in each of those samples, and looking at the histogram of that dataset. As there are a large number of possible samples, we have resorted to an empirical distribution based on some of them. However, it turns out that in this case there is a straightforward formula for the probabilities.</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Binomial-distribution-with-parameters-$n=100$-and-$p=0.26$">Binomial distribution with parameters $n=100$ and $p=0.26$<a class="anchor-link" href="#Binomial-distribution-with-parameters-$n=100$-and-$p=0.26$">¶</a></h3><p>This is the name of the probability distribution of the number of 1's in a sample of size 100 drawn at random <strong>with</strong> replacement from a population consisting of 26% 1's and 74% 0's. It is also a good approximation if the sample is drawn <strong>without</strong> replacement from a population that is very large compared to the sample, as is the case in our example involving the jury panel.</p>
<p>In general, the binomial distribution is the probability distribution of the number of successes in a fixed, known number of repeated success/failure trials, where the result of any group of trials does not affect chances for the others. Examples are:</p>
<ul>
<li>the probability distribution of the number of sixes in repeated rolls of a die</li>
<li>the probability distribution of the number of heads in repeated tosses of a coin (fair or unfair)</li>
<li>the probability distribution of the number of voters who will vote for a particular candidate, assuming a random sample of voters that is essentially the same as a sample drawn at random with replacement</li>
</ul>
<p>The assumption that no group of trials influences any others is called <em>independence</em>. Two events are independent if knowing that one of them has happened does not change chances for the other. For example, knowing that the first roll of a die resulted in the face with two spots does not change the chances for any face appearing on other rolls. We say that the rolls are <em>independent</em> of each other.</p>
<p>The binomial distribution has two <em>parameters</em>: the number of trials $n$, and the probability $p$ of success on each single trial. A parameter is a constant associated with a distribution. Here is a histogram of the distribution for $n = 100$ and $p = 0.26$. It is the exact distribution of probabilities for the number of black jurors in a panel of 100 jurors, drawn under the null hypothesis of random selection from an eligible population in which 26% are black. Notice that the distribution is a smooth version of its empirical approximation above.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">probs</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">101</span><span class="p">),</span> <span class="mi">100</span><span class="p">,</span> <span class="o">.</span><span class="mi">26</span><span class="p">)</span>
<span class="n">k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">101</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">Table</span><span class="p">([</span><span class="n">k</span><span class="p">,</span> <span class="n">probs</span><span class="p">],</span> <span class="p">[</span><span class="s1">'k'</span><span class="p">,</span> <span class="s1">'P(k black in 100)'</span><span class="p">])</span>
<span class="n">dist</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">counts</span><span class="o">=</span><span class="s1">'k'</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">100.6</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plots</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plots</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">plots</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'number black in sample of 100 (under null)'</span><span class="p">)</span>
<span class="n">plots</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Probability Distribution'</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.text.Text at 0x10aaf2eb8&gt;</pre></div>
<div class="output_png output_subarea ">
<img src="/notebooks-images/Binomial_8_1.png"/></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="The-c.d.f.-of-the-binomial">The c.d.f. of the binomial<a class="anchor-link" href="#The-c.d.f.-of-the-binomial">¶</a></h3><p>We have seen the cumulative distribution function (c.d.f.) of the normal distribution evaluated at any point gives the proportion of area under the normal curve to the left of the point. So also the c.d.f. of the binomial distribution evaluated at a value gives the area of the bars of the histogram from 0 through the value.</p>
<p>The function is <code>stats.binom.cdf</code>. It takes as its arguments the value $k$, and the binomial parameters $n$ and $p$. It evaluates to the total probability of the bars $0, 1, 2, \ldots , k$.</p>
<h4 id="Example-1.">Example 1.<a class="anchor-link" href="#Example-1.">¶</a></h4><p>To find the $P$-value of the test using the binomial distribution, we will start by finding the chance of 8 or fewer black men in the sample:</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Chance of "8 or fewer black in sample"</span>
<span class="c1"># = all the area in the bars 8 and below</span>

<span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mf">0.26</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_text output_subarea output_execute_result">
<pre>4.7347949978893112e-06</pre></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The chance is tiny, no matter whether you use a one-tailed test of a two-tailed test. This is consistent with there being no visible probability over the 0-8 range in the probability histogram above.</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can use the binomial distribution to find $P$-values in other contexts too.</p>
<h4 id="Example-2.">Example 2.<a class="anchor-link" href="#Example-2.">¶</a></h4><p>In a blind taste test, 38 out of 64 people liked Drink A better than Drink B. A skeptic has an argument with the manufactuer of Drink A. Here are their positions.</p>
<p><strong>Skeptic:</strong> That could have happened just by chance.</p>
<p><strong>Manufacturer of Drink A:</strong> No way was that by chance.</p>
<p>State null and alternative hypotheses, and perform an appropriate test.</p>
<p><strong>Formal null hypothesis:</strong> The test results are like the number of heads in 64 tosses of a fair coin.</p>
<p><strong>Formal alternative hypothesis:</strong> The test results are not like heads in tosses of a coin.</p>
<p>If the null hypothesis were true, we would expect 32 "heads", that is, people who prefer Drink A. We got 38 heads. So to find the $P$-value, we will need to start with the chance of getting 38 or more heads in 64 tosses. We can calculate this using <code>stats.norm.cdf</code> after noting that the complement of "38 or more" is "37 or fewer".</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Chance of 38 or more heads in 64 tosses of a fair coin:</span>

<span class="mi">1</span> <span class="o">-</span> <span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="mi">37</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_text output_subarea output_execute_result">
<pre>0.084321455719851723</pre></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If the taste test had been based on tosses of a coin, there would be over an 8.4% chance of getting 38 or more "preferences" of Drink A. If you use the 5% cutoff, you would be justified in saying the data still support the null hypothesis, whether you use a one-tailed test or a two-tailed test.</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Example-3.">Example 3.<a class="anchor-link" href="#Example-3.">¶</a></h4><p>Find the chance of exactly 50 heads in 100 tosses of a fair coin.</p>
<p>This is the chance of 0 through 50 heads minus the chance of 0 through 49 heads:</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">-</span> <span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="mi">49</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_text output_subarea output_execute_result">
<pre>0.079589237387179379</pre></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Notice that the chance is only about 8%. The chance of 500 heads in 1000 tosses is even smaller, just about 2.5%.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">-</span> <span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="mi">499</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_text output_subarea output_execute_result">
<pre>0.025225018177683411</pre></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Notice that the chance of <em>exactly half</em> heads decreases as the number of tosses increases; indeed, it goes to zero. The law of averages says that the chance of <em>about half</em> heads increases. The word <em>about</em> is crucial; later in this section we will discuss how to quantify it.</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The <code>stats</code> module contains a function that allows you to calculate the chance of exactly $k$ successes in a binomial model, without using <code>stats.binom.cdf</code> twice. The function is called <code>stats.binom.pmf</code>, for "probability mass function". Its arguments are the same as for <code>stats.binom.cdf</code>, but it evaluates to the probability of exactly $k$ successes.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Probability mass function at k</span>
<span class="c1"># = chance of exactly k heads</span>

<span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_text output_subarea output_execute_result">
<pre>0.079589237387178879</pre></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>How does Python calculate the binomial probabilities? Let us see if we can figure out the answer. We will do so in a simpler context.</p>
<p><strong>Example 4.</strong> In roulette, there are 18 chances in 38 to win a bet on "red". Suppose you bet on red on 5 different spins of the wheel. What is the chance that you win exactly 3 times?</p>
<p>The number of bets won has the binomial distribution with parameters $n=5$ and $p=18/38$. Here is a histogram of the distribution, and the chance of exactly 3 wins.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">probs</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">),</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">18</span><span class="o">/</span><span class="mi">38</span><span class="p">)</span>
<span class="n">k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">Table</span><span class="p">([</span><span class="n">k</span><span class="p">,</span> <span class="n">probs</span><span class="p">],</span> <span class="p">[</span><span class="s1">'k'</span><span class="p">,</span> <span class="s1">'P(k wins in 5 bets on red)'</span><span class="p">])</span>
<span class="n">dist</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">counts</span><span class="o">=</span><span class="s1">'k'</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">5.6</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plots</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span>
<span class="n">plots</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'number of wins in 5 bets on red'</span><span class="p">)</span>
<span class="n">plots</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Probability Distribution'</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.text.Text at 0x10acfcfd0&gt;</pre></div>
<div class="output_png output_subarea ">
<img src="/notebooks-images/Binomial_23_1.png"/></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># chance of exactly 3 wins</span>

<span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">18</span><span class="o">/</span><span class="mi">38</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_text output_subarea output_execute_result">
<pre>0.29441472251311429</pre></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>According to <code>stats.binom.pmf</code>, there is just under 30% chance that you win exactly 3 out of 5 bets on red. To see where this number comes from, let us try writing out some ways in which we could win 3 out of 5 bets.</p>
<ul>
<li>WLWLW</li>
<li>WWWLL</li>
<li>LWWWL</li>
</ul>
<p>and so on.</p>
<p>Each way is a pattern consisting of 3 W's and 2 L's. Each of these patterns has chance $(18/38)^3 (20/38)^2$. The chance of winning exactly 3 times is the total chance of all these ways:</p>
$$
P(\mbox{3 wins among 5 bets on red}) ~=~ \mbox{number of patterns of 3 W's and 2 L's} \cdot (18/38)^3 (20/38)^2
$$<p><strong>A fact of mathematics.</strong> The number of patterns consisting of 3 W's and 2 L's is called <em>5 choose 3</em> and is calculated as follows:</p>
$$
\mbox{number of patterns of 3 W's and 2 L's} 
~=~ {5 \choose 3}
~=~ \frac{5!}{3!2!} ~=~ 10
$$<p>So</p>
$$
P(\mbox{3 wins among 5 bets on red}) = 10 \cdot (18/38)^3(20/38)^2
$$<p>This is calculated in the cell below, and agrees with the answer obtained earlier by using <code>stats.binom.pmf</code>.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="mi">10</span><span class="o">*</span><span class="p">((</span><span class="mi">18</span><span class="o">/</span><span class="mi">38</span><span class="p">)</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">20</span><span class="o">/</span><span class="mi">38</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
</pre></div></div></div>
<div class="output_text output_subarea output_execute_result">
<pre>0.2944147225131143</pre></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Binomial-distribution-with-parameters-$n$-and-$p$">Binomial distribution with parameters $n$ and $p$<a class="anchor-link" href="#Binomial-distribution-with-parameters-$n$-and-$p$">¶</a></h2><p>We can generalize our observations above to identify the probability distribution of the number of successes in $n$ repeated, independent, success/failure trials, with probability $p$ of success on each single trial. This is the binomial distribution with parameters $n$ and $p$.</p>
$$
P(k \mbox{ successes in }n \mbox{ trials}) ~=~ {n \choose k} p^k (1-p)^{n-k}
~=~ \frac{n!}{k!(n-k)!} p^k (1-p)^{n-k} ~~~ \mbox{for} ~ 0 \le k \le n
$$</div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It is worth recalling that $0!$ is defined to be 1, so that the answers make sense in the two edge cases $k=0$ and $k=n$. Notice also that when we say "$k$ successes", we mean "exactly $k$ successes".</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="More-than-two-categories:-Multinomial-Probabilities">More than two categories: Multinomial Probabilities<a class="anchor-link" href="#More-than-two-categories:-Multinomial-Probabilities">¶</a></h3><p>The binomial can be generalized to the case where the population splits into more than two categories. This is called the <em>multinomial</em> model. That is why the NumPy method to simulate the draws is called <code>np.random.multinomial</code>.</p>
<p><strong>Example 5.</strong> In a population, 20% of the people are men, 30% are women, and 50% are children. Six people are drawn at random with replacement. Find the chance that the sample contains 1 man, 2 women, and 3 children.</p>
<p>The answer is a straightforward generalization of the binomial formula above.</p>
$$
P(\mbox{1 man, 2 women, 3 children}) ~=~
\frac{6!}{1!2!3!} (0.2)^1 (0.3)^2 (0.5)^3
$$</div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Expected-Value-and-Standard-Error-of-the-Binomial">Expected Value and Standard Error of the Binomial<a class="anchor-link" href="#Expected-Value-and-Standard-Error-of-the-Binomial">¶</a></h3><p>In an earlier section, we saw that if we had $n$ independent, repeated, success/failure trials with probability $p$ of success on each trial, then:</p>
$$
\mbox{expected proportion of successes} ~=~ p
$$$$
\mbox{SE of the proportion of successes} ~=~ \sqrt{ \frac{p(1-p)}{n} }
$$<p>Now the number of success is just $n$ times the proportion of successes. Hence</p>
$$
\mbox{expected number of successes} ~=~ np
$$$$
\mbox{SE of the number of successes} ~=~ \sqrt{np(1-p)}
$$</div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Example 6.</strong> What is the expected value and standard error of the number of heads in 100 tosses of a coin?</p>
<p>According to the formulas above, the expected number of heads is $100 \times 0.5 = 50$ and the standard error is $\sqrt{100 \times 0.5 \times 0.5} = 5$. That the expected value should be 50 is easy to guess. To visualize the standard error, it helps to see the histogram of the binomial distribution with $n=100$ and $p=0.5$.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">probs</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">71</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
<span class="n">k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">71</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">Table</span><span class="p">([</span><span class="n">k</span><span class="p">,</span> <span class="n">probs</span><span class="p">],</span> <span class="p">[</span><span class="s1">'k'</span><span class="p">,</span> <span class="s1">'P(k heads in 100 tosses)'</span><span class="p">])</span>
<span class="n">dist</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">counts</span><span class="o">=</span><span class="s1">'k'</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">29.5</span><span class="p">,</span> <span class="mf">70.6</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plots</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span><span class="mi">75</span><span class="p">)</span>
<span class="n">plots</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'number of heads in 100 tosses'</span><span class="p">)</span>
<span class="n">plots</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Probability Distribution'</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.text.Text at 0x10afab8d0&gt;</pre></div>
<div class="output_png output_subarea ">
<img src="/notebooks-images/Binomial_32_1.png"/></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Notice the beautifully symmetric, normal shape, centered at 50. The points of inflection of the curve are at 45 and 55, one standard error away from the expected value. That is consistent with the points "mean $\pm$ SD" being the points of inflecion of a normal curve.</p>
<p>Notice also that the number of heads is most likely to be in the 35-65 range, that is, within 3 standard errors of the expected value. Even though the possible values are 0 through 100, the probable values are in a much smaller range.</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Example 7.</strong> What is the chance that the proportion of heads will be between 0.45 and 0.55, if you toss a coin</p>
<p>(a) 100 times?</p>
<p>(b) 1000 times?</p>
<p>We can answer both of these questions by using <code>stats.binom.cdf</code>. We do have to be consistent in our definition of "between". We will take it to mean "between 0.45 and 0.55, inclusive". That is, we will include both the endpoints in the interval.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#(a) 100 tosses; chance that the proportion of heads is between 0.45 and 0.55</span>

<span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="mi">55</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">-</span> <span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="mi">44</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_text output_subarea output_execute_result">
<pre>0.72874697592616577</pre></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#(a) 1000 tosses; chance that the proportion of heads is between 0.45 and 0.55</span>

<span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="mi">550</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">-</span> <span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="mi">449</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_text output_subarea output_execute_result">
<pre>0.99860825840557732</pre></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Notice how the chance rose from about 73% to well over 99%. That's because of the law of averages. The chance that the proportion of heads is in any fixed interval around 0.5 goes up as the number of tosses increases.</p></div></div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We could also have given rough approximations to these answers by using the normal approximation. In both cases, the proportion of heads is expected to be 0.5.</p>
<ul>
<li>When there are 100 tosses, the standard error of the proportion is $\sqrt{0.5 \times 0.5 /100} = 0.05$.</li>
<li>When there are 1000 tosses, the standard error of the proportion is $\sqrt{0.5 \times 0.5 /1000} = 0.0158$.</li>
</ul>
<p>The corresponding normal curves give the following approximations. You can see that the approximation is better when the number of tosses is larger. Because the normal curve is continuous, we need not worry about including or excluding endpoints; each single point corresponds to an area of 0.</p></div></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Normal approximation to the chance of between 0.45 and 0.55 heads in 100 tosses</span>

<span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span> <span class="o">-</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="mf">0.45</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_text output_subarea output_execute_result">
<pre>0.68268949213708607</pre></div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Normal approximation to the chance of between 0.45 and 0.55 heads in 1000 tosses</span>

<span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.0158</span><span class="p">)</span> <span class="o">-</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="mf">0.45</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.0158</span><span class="p">)</span>
</pre></div></div></div>
<div class="output_text output_subarea output_execute_result">
<pre>0.99844680743966796</pre></div></div>