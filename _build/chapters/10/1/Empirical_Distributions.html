---
redirect_from:
  - "/chapters/10/1/empirical-distributions"
interact_link: content/chapters/10/1/Empirical_Distributions.ipynb
kernel_name: python3
has_widgets: false
title: |-
  Empirical Distributions
prev_page:
  url: /chapters/10/Sampling_and_Empirical_Distributions.html
  title: |-
    Sampling and Empirical Distributions
next_page:
  url: /chapters/10/2/Sampling_from_a_Population.html
  title: |-
    Sampling from a Population
comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---
<div class="jb_cell tag_remove_input">

<div class="cell border-box-sizing code_cell rendered">

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Empirical-Distributions">Empirical Distributions<a class="anchor-link" href="#Empirical-Distributions"> </a></h3><p>In data science, the word "empirical" means "observed". Empirical distributions are distributions of observed data, such as data in random samples.</p>
<p>In this section we will generate data and see what the empirical distribution looks like.</p>
<p>Our setting is a simple experiment: rolling a die multiple times and keeping track of which face appears. The table <code>die</code> contains the numbers of spots on the faces of a die. All the numbers appear exactly once, as we are assuming that the die is fair.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">die</span> <span class="o">=</span> <span class="n">Table</span><span class="p">()</span><span class="o">.</span><span class="n">with_column</span><span class="p">(</span><span class="s1">&#39;Face&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">die</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<table border="1" class="dataframe">
    <thead>
        <tr>
            <th>Face</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>1   </td>
        </tr>
        <tr>
            <td>2   </td>
        </tr>
        <tr>
            <td>3   </td>
        </tr>
        <tr>
            <td>4   </td>
        </tr>
        <tr>
            <td>5   </td>
        </tr>
        <tr>
            <td>6   </td>
        </tr>
    </tbody>
</table>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="A-Probability-Distribution">A Probability Distribution<a class="anchor-link" href="#A-Probability-Distribution"> </a></h3><p>The histogram below helps us visualize the fact that every face appears with probability 1/6. We say that the histogram shows the <em>distribution</em> of probabilities over all the possible faces. Since all the bars represent the same percent chance, the distribution is called <em>uniform on the integers 1 through 6.</em></p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">die_bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">6.6</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">die</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span> <span class="o">=</span> <span class="n">die_bins</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../../images/chapters/10/1/Empirical_Distributions_4_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Variables whose successive values are separated by the same fixed amount, such as the values on rolls of a die (successive values separated by 1), fall into a class of variables that are called <em>discrete</em>. The histogram above is called a <em>discrete</em> histogram. Its bins are specified by the array <code>die_bins</code> and ensure that each bar is centered over the corresponding integer value.</p>
<p>It is important to remember that the die can't show 1.3 spots, or 5.2 spots â€“ it always shows an integer number of spots. But our visualization spreads the probability of each value over the area of a bar. While this might seem a bit arbitrary at this stage of the course, it will become important later when we overlay smooth curves over discrete histograms.</p>
<p>Before going further, let's make sure that the numbers on the axes make sense. The probability of each face is 1/6, which is 16.67% when rounded to two decimal places. The width of each bin is 1 unit. So the height of each bar is 16.67% per unit. This agrees with the horizontal and vertical scales of the graph.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Empirical-Distributions">Empirical Distributions<a class="anchor-link" href="#Empirical-Distributions"> </a></h3><p>The distribution above consists of the theoretical probability of each face. It is not based on data. It can be studied and understood without any dice being rolled.</p>
<p><em>Empirical distributions,</em> on the other hand, are distributions of observed data. They can be visualized by <em>empirical histograms</em>.</p>
<p>Let us get some data by simulating rolls of a die. This can be done by sampling at random with replacement from the integers 1 through 6. We have used <code>np.random.choice</code> for such simulations before. But now we will introduce a Table method for doing this. This will make it possible for us to use our familiar Table methods for visualization.</p>
<p>The Table method is called <code>sample</code>. It draws at random with replacement from the rows of a table. Its argument is the sample size, and it returns a table consisting of the rows that were selected. An optional argument <code>with_replacement=False</code> specifies that the sample should be drawn without replacement, but that does not apply to rolling a die.</p>
<p>Here are the results of 10 rolls of a die.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">die</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<table border="1" class="dataframe">
    <thead>
        <tr>
            <th>Face</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>1   </td>
        </tr>
        <tr>
            <td>2   </td>
        </tr>
        <tr>
            <td>3   </td>
        </tr>
        <tr>
            <td>4   </td>
        </tr>
        <tr>
            <td>4   </td>
        </tr>
        <tr>
            <td>1   </td>
        </tr>
        <tr>
            <td>1   </td>
        </tr>
        <tr>
            <td>2   </td>
        </tr>
        <tr>
            <td>6   </td>
        </tr>
        <tr>
            <td>2   </td>
        </tr>
    </tbody>
</table>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can use the same method to simulate as many rolls as we like, and then draw empirical histograms of the results. Because we are going to do this repeatedly, we define a function <code>empirical_hist_die</code> that takes the sample size as its argument, rolls a die as many times as its argument, and then draws a histogram of the observed results.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">empirical_hist_die</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="n">die</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span> <span class="o">=</span> <span class="n">die_bins</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Empirical-Histograms">Empirical Histograms<a class="anchor-link" href="#Empirical-Histograms"> </a></h3><p>Here is an empirical histogram of 10 rolls. It doesn't look very much like the probability histogram above. Run the cell a few times to see how it varies.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">empirical_hist_die</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../../images/chapters/10/1/Empirical_Distributions_11_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>When the sample size increases, the empirical histogram begins to look more like the histogram of theoretical probabilities.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">empirical_hist_die</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../../images/chapters/10/1/Empirical_Distributions_13_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">empirical_hist_die</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../../images/chapters/10/1/Empirical_Distributions_14_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As we increase the number of rolls in the simulation, the area of each bar gets closer to 16.67%, which is the area of each bar in the probability histogram.</p>
<h3 id="The-Law-of-Averages">The Law of Averages<a class="anchor-link" href="#The-Law-of-Averages"> </a></h3><p>What we have observed above is an instance of a general rule.</p>
<p>If a chance experiment is repeated independently and under identical conditions, then, in the long run, the proportion of times that an event occurs gets closer and closer to the theoretical probability of the event.</p>
<p>For example, in the long run, the proportion of times the face with four spots appears gets closer and closer to 1/6.</p>
<p>Here "independently and under identical conditions" means that every repetition is performed in the same way regardless of the results of all the other repetitions.</p>

</div>
</div>
</div>
</div>

 

